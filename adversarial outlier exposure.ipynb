{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adversarial Outlier Exposure\n",
    "\n",
    "from the paper Adversarial Outlier Exposure, presented at SKILL GI 2023 in Berlin by Thomas Botschen (OVGU Magdeburg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_ood.loss import OutlierExposureLoss\n",
    "from attacks import fgsm_softmax, pgd_softmax, mifgsm_softmax\n",
    "from eval import create_metrics_dataset\n",
    "from utils import  get_training_datasets, get_model, check_for_epsilon_order"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### edit the config file to configure experiments as you need"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "args = OmegaConf.load(\"config.yaml\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model': 'wrn', 'dataset_in': 'cifar10', 'dataset_out': 'GAN_IMG', 'epochs': 1, 'learning_rate': 0.001, 'batch_size': 256, 'oe_batch_size': 256, 'test_bs': 256, 'momentum': 0.9, 'decay': 0.0005, 'score': 'softmax', 'adv_oe': 'FGSM', 'eps_oe': 0.07, 'alpha_oe': 0.03, 'steps_oe': 20, 'epsilon_order': False}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_adversarial_outlier(args, model, inlier, outlier, target_inlier, target_outlier, eps_oe, device):\n",
    "    attack_methods = {\n",
    "        \"None\": lambda *args, **kwargs: outlier,\n",
    "        \"FGSM\": fgsm_softmax,\n",
    "        \"PGD\": pgd_softmax,\n",
    "        \"MIFGSM\": mifgsm_softmax\n",
    "    }\n",
    "\n",
    "    if args.score == \"softmax\" and args.adv_oe in attack_methods:\n",
    "        attack_method = attack_methods[args.adv_oe]\n",
    "        common_kwargs = {\n",
    "            \"model\": model,\n",
    "            \"inlier\": inlier,\n",
    "            \"outlier\": outlier,\n",
    "            \"target_inlier\": target_inlier,\n",
    "            \"target_outlier\": target_outlier,\n",
    "            \"eps_oe\": eps_oe,\n",
    "            \"device\": device\n",
    "        }\n",
    "        if args.adv_oe in [\"PGD\", \"MIFGSM\"]:\n",
    "            common_kwargs.update({\n",
    "                \"alpha_oe\": args.alpha_oe,\n",
    "                \"steps_oe\": args.steps_oe\n",
    "            })\n",
    "        return attack_method(**common_kwargs)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using GPU for computations.\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"CUDA is not available. Using CPU for computations.\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def create_data_loader(data, batch_size, shuffle, num_workers=0, pin_memory=True):\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle,\n",
    "                                       num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "def prepare_data_loaders(args):\n",
    "    # Retrieve logic data\n",
    "    train_data_in, train_data_out = get_training_datasets(args)\n",
    "\n",
    "    # Define data loaders\n",
    "    train_loader_in = create_data_loader(train_data_in, args.batch_size, shuffle=True)\n",
    "    train_loader_out = create_data_loader(train_data_out, args.oe_batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader_in, train_loader_out\n",
    "\n",
    "\n",
    "def create_optimizer_and_scheduler(model, args, train_loader_in):\n",
    "    # define logic parameters\n",
    "    def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "        return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "                1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), args.learning_rate, momentum=args.momentum,\n",
    "        weight_decay=args.decay, nesterov=True)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda step: cosine_annealing(\n",
    "            step,\n",
    "            args.epochs * len(train_loader_in),\n",
    "            1,  # since lr_lambda computes multiplicative factor\n",
    "            1e-6 / args.learning_rate))\n",
    "\n",
    "    return optimizer, scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # GPU acceleration\n",
    "    device = get_device()\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    model = get_model(args)\n",
    "\n",
    "    # define data loaders\n",
    "    train_loader_inlier, train_loader_outlier = prepare_data_loaders(args)\n",
    "\n",
    "    # define optimizer and scheduler\n",
    "    optimizer, scheduler = create_optimizer_and_scheduler(model, args, train_loader_inlier)\n",
    "\n",
    "    criterion = OutlierExposureLoss()\n",
    "\n",
    "    def train_adversarial_default(epoch):\n",
    "        loss_avg = 0.0\n",
    "        model.train()  # enter train mode\n",
    "        print(\"Starting adversarial training epoch %d\" % epoch)\n",
    "        print(\"Length of train_loader_inlier: \", len(train_loader_inlier))\n",
    "        print(\"Length of train_loader_outlier: \", len(train_loader_outlier))\n",
    "\n",
    "        for in_set, out_set in tqdm(zip(train_loader_inlier, train_loader_outlier), total=len(train_loader_inlier)):\n",
    "\n",
    "            # define variables\n",
    "            inlier = in_set[0]\n",
    "            outlier = out_set[0]\n",
    "            target_inlier = in_set[1]\n",
    "            target_outlier = out_set[1]\n",
    "\n",
    "            # stop if we have covered the entire outlier dataset and we have remains (10000%64=16 -> the code would crash)\n",
    "            if len(outlier) < args.oe_batch_size:\n",
    "                break\n",
    "\n",
    "            # check for custom epsilon order\n",
    "            eps_oe = check_for_epsilon_order(epoch, args)\n",
    "\n",
    "            # perform adversarial attack on outliers\n",
    "            perturbed_outlier = generate_adversarial_outlier(args, model, inlier, outlier, target_inlier,\n",
    "                                                             target_outlier, eps_oe, device)\n",
    "\n",
    "            # concatenate inlier and perturbed outlier\n",
    "            data = torch.cat((inlier.to(device), perturbed_outlier.to(device)), 0).to(device)\n",
    "\n",
    "            # forward\n",
    "            data = data.float()\n",
    "            x = model(data)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(x, torch.cat((target_inlier.to(device), target_outlier.to(device)), 0))\n",
    "\n",
    "            # update parameters\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "            # exponential moving average\n",
    "            loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "        train_loss = loss_avg\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def run_training():\n",
    "        training_start = time.time()\n",
    "        losses = []\n",
    "\n",
    "        if args.dataset_in in [\"cifar10\", \"cifar100\"]:\n",
    "            for epoch in range(args.epochs):\n",
    "                begin_epoch = time.time()\n",
    "\n",
    "                train_loss_epoch = train_adversarial_default(epoch)\n",
    "                losses.append({\"epoch\": epoch, \"loss\": round(train_loss_epoch, 4)})\n",
    "\n",
    "                print(\n",
    "                    f'Epoch {epoch + 1:3d} | Time {int(time.time() - begin_epoch):5d} | Train Loss {train_loss_epoch:.4f}')\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown dataset: {}\".format(args.dataset_in))\n",
    "\n",
    "        time_needed = time.time() - training_start\n",
    "        print(f\"Finished training in {time_needed}\")\n",
    "\n",
    "\n",
    "        aurocs = create_metrics_dataset(model=model, dataset_to_test=args.dataset_in)\n",
    "\n",
    "        print(aurocs)\n",
    "\n",
    "\n",
    "    # now run the program :)\n",
    "    run_training()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU for computations.\n",
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Starting adversarial training epoch 0\n",
      "Length of train_loader_inlier:  196\n",
      "Length of train_loader_outlier:  196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 195/196 [02:43<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Time   163 | Train Loss 0.6264\n",
      "Finished training in 163.48838782310486\n",
      "Files already downloaded and verified\n",
      "Evaluating textures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:49<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lsun resize...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lsun crop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinyimagenet crop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinyimagenet resize...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gaussian noise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:08<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating uniform noise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:06<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'textures', 'metrics': {'AUROC': 0.8869585394859314, 'AUPR-IN': 0.803619921207428, 'AUPR-OUT': 0.9354285001754761, 'FPR95TPR': 0.3813000023365021}}, {'dataset': 'lsun resize', 'metrics': {'AUROC': 0.9252873659133911, 'AUPR-IN': 0.9017477631568909, 'AUPR-OUT': 0.9421669244766235, 'FPR95TPR': 0.22669999301433563}}, {'dataset': 'lsun crop', 'metrics': {'AUROC': 0.9566106796264648, 'AUPR-IN': 0.9464101791381836, 'AUPR-OUT': 0.9658747911453247, 'FPR95TPR': 0.14949999749660492}}, {'dataset': 'tinyimagenet crop', 'metrics': {'AUROC': 0.9426779747009277, 'AUPR-IN': 0.9304371476173401, 'AUPR-OUT': 0.9537640810012817, 'FPR95TPR': 0.1981000006198883}}, {'dataset': 'tinyimagenet resize', 'metrics': {'AUROC': 0.9093412160873413, 'AUPR-IN': 0.8827979564666748, 'AUPR-OUT': 0.9282353520393372, 'FPR95TPR': 0.2734000086784363}}, {'dataset': 'gaussian noise', 'metrics': {'AUROC': 0.9388073682785034, 'AUPR-IN': 0.3222408890724182, 'AUPR-OUT': 0.9968499541282654, 'FPR95TPR': 0.1542000025510788}}, {'dataset': 'uniform noise', 'metrics': {'AUROC': 0.9465610980987549, 'AUPR-IN': 0.40109899640083313, 'AUPR-OUT': 0.9972383975982666, 'FPR95TPR': 0.1599999964237213}}, {'dataset': 'average', 'metrics': {'AUROC': 0.9294634631701878, 'AUPR-IN': 0.7411932647228241, 'AUPR-OUT': 0.9599368572235107, 'FPR95TPR': 0.2204571430172239}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "outlier_exposure",
   "language": "python",
   "display_name": "Outlier_Exposure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
